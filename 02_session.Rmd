---
title: "session 2 notes"
author: "Tim Riffe"
date: "2024-07-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# grab the data, load tidyverse

```{r}
library(tidyverse)
ES <- read_csv("https://github.com/timriffe/BSSD2024Module2/raw/master/data/ES_mort.csv.gz",
               show_col_types = FALSE)
# ES <- read_csv("data/ES_mort.csv.gz")
```
The second line is for reading in the file locally, where I emphasize that we should always remember to keep the path short, and relative to our current project location.

If your internet is super slow, you can increase the timeout for downloading like so:
```{r}
options(timeout = 1000)
```
This will let your machine keep trying for longer to download a file.

## Compare mortality rates

I spoke for a long time about how it's tough to compare these two mortality schedules because 1. rates are in hard-to-understand units, 2. there are 111 values per mortality schedule. We should want a reasonable summary measure (a single value), and for it to be in understandable units. Like life expectancy. Or the modal age at death. Or something like that.
```{r, warning = FALSE}
ES |> 
  filter(year %in% c(1930,2019),
         sex == "female") |> 
  ggplot(aes(x = age, y = mx, color = as.factor(year))) +
  geom_line() +
  scale_y_log10() +
  theme_minimal()
```

This second plot was just to make a point that looking at rate differences in pointless, because a value of .005 might be a very small difference or a very big difference, depending on what age we're in.
```{r}
ES |> 
  filter(year %in% c(1930,2019),
         sex == "female",
         age < 90) |> 
  select(year, age, mx) |> 
  # year moves to columns here:
  pivot_wider(names_from = year, values_from = mx) |> 
  mutate(mx_diff = `1930` - `2019`) |> 
  ggplot(aes(x = age, y = mx_diff)) +
  geom_line()
```
Rate ratios are also not great as the *final* value to report. They are good for getting a sense of how rate differences vary over age, relative to overall levels, BUT, again with rate ratios we lose a sense of scale. If you want to report group differences, please don't stop the exercise with rate ratios- continue converting units until you arrive at something actually intelligible. Remember also to always plot rate ratios (or ratios of any kind) with a logged axis.

# $q_x$ conditional death probabilities

Conditional death probabilities means the probability of dying in an interval conditional on surviving into the interval.
$$ q_x = \frac{m_x}{1 + (1 - a_x)m_x} $$

So, the first thing we want is to transform rates to probabilities, behold the above formula. Where on earth is it from? This I encourage you to simply look up whenever you need it rather than memorizing it. I would look it up from here <https://www.mortality.org/File/GetDocument/Public/Docs/MethodsProtocolV6.pdf> or the Preston book whenever I need it. But, look at that tiny variable in the denominator $a_x$: that has to come from somewhere... 

NOTE: annotate this
```{r}
mx_to_ax_simple <- function(mx, age, n){
  tibble(mx,age,n) |> 
    mutate(ax = case_when(
      age == 0 & mx < .02012 ~ .14916 - 2.02536 * mx,
      age == 0 & mx < .07599 ~ 0.037495 + 3.57055 * mx,
      age == 0 & mx >= .07599 ~ 0.30663,
      age == max(age) & mx == 0 ~ .5,
      age == max(age) ~ 1 / mx,
      TRUE ~ n / 2)) |> 
    pull(ax)
}
```

Now we can implement the transformation to $q_x$

We have more details to attend to in this function!
```{r}
mx_to_qx <- function(mx, ax){
  qx <- mx / (1 + (1 - ax) * mx)
  # NEW I
  N <- length(qx)
  qx[N] <- 1
  # NEW II
  qx[qx > 1] <- 1
  return(qx)
}
```

# survivorship: $l_x$

In words: to survive from birth to age 3, you need to survive from 0 to your first birthday, and then from your first to your second birthday, and then from your second to your third birthday. Each birthday you get a new set of dice to roll. Age 0 starts off with a clean initial population of 1.

$$ \ell_x = \prod _{t=0}^{x-1} (1 - q_t) \quad \forall x>0$$
$$ \ell_0 = 1 $$

Notes: the `cumprod()` part of this transformation is the most important part.
```{r}
qx_to_lx <- function(qx, radix = 1){
  N  <- length(qx)
  lx <- c(1, cumprod(1 - qx[-N]))
  lx <- lx * radix
  return(lx)
}
```
$l_x$ gives the first glance at LE that we have: it's the area under this curve, but we'd want to do a better job integrating that area. We tried in the session by taking $(\sum \ell_x)-.5$, and it was a really good estimate :-)

From the survival curve, you can find quantiles, e.g. the median age at death. Or you can

# deaths distribution $d_x$

The death distribution is a probability distribution: the probability of dying at age $x$ seen from the perspective of a newborn in the synthetic population. The logic: first you need to chain the probabilities of surviving through each single age until you reach $x$ (a.k.a $\ell_x$) then subject to the death probability that age $q_x$. 

$$ d_x = \ell_x \cdot q_x $$

Here, I went on a long tangent about the modal age at death, which is great because 
1. it's more stable than $e_0$ (life expectancy at birth)
2. the data requirements for seeings it are far less strict, which means
3. you can get a time series of COHORT modal ages at death even

## $L_x$ is the person-years lived in each age group

This is all about figuring out the most precise way to integrate under $\ell_x$ for each single age step. Taking a rectangle at the level of $\ell_x$ is too high, whereas a rectangle at $\ell_{x+1}$ is too low a value. In this formula, if $a_x = .5$, it amounts to the same thing as $(\ell_x + \ell_{x+1})/2$

$$ L_x = \ell_x - (1 - a_x)d_x \quad \forall x <\omega$$
$$ L_\omega = d_\omega \cdot a_\omega $$

```{r}
lxdx_to_Lx <- function(lx,dx,ax){
  Lx    <- lx - (1 - ax) * dx
  N     <- length(lx)
  Lx[N] <- ax[N] * lx[N]
  return(Lx)
}
```

# Tx Total years lived above x

$T_x$ is an instrumental lifetable column, needed here and there, but not something you look at for demographic insight.

$$ T_x = \sum_x^\omega L_x$$
```{r}
Lx_to_Tx <- function(Lx){
  Tx <- 
    Lx |> 
    rev() |> 
    cumsum() |> 
    rev() 
  return(Tx)
}
```

Now we're ready to calculate full lifetables
$$ e_x = \frac{T_x}{\ell_x}$$

This code chunk is the final version of the code chunk, which we had been building and executing in order to visualize lifetable functions and calculate life expectancy estimates at different levels of approximation.

```{r}
LT <- 
 ES |> 
   group_by(sex, year) |> 
   mutate(n = rep(1, n()),
          # add note here
          mx = if_else(is.na(mx), .5, mx),
          ax = mx_to_ax_simple(mx, age, n),
          qx = mx_to_qx(mx, ax),
          lx = qx_to_lx(qx),
          dx = lx * qx,
          Lx = lxdx_to_Lx(lx, dx, ax),
          Tx = Lx_to_Tx(Lx),
          ex = Tx / lx) 
```


# Exercises

1. make a plot of $e_0$ over time

```{r}
LT |> 
  filter(age == 0) |> 
  ggplot(aes(x = year, y = ex, color = sex)) +
  geom_line() +
  theme_minimal()
```

2. make plot of $M$ (modal age at death), be sure to filter out ages < 10 for this.

```{r}
LT |> 
  filter(age > 10) |> 
  group_by(sex, year) |> 
  summarize(M = age[dx == max(dx)] + ax[dx == max(dx)],
            .groups = "drop") |> 
  ggplot(aes(x = year, y = M, color = sex)) +
  geom_step() +
  theme_minimal()
```

3. find a mortality shock year from (1), and compare it's $\ell_x$ and $d_x$ with those of a typical year.

```{r, warning = FALSE}
LT |> 
  filter(year %in% c(1917,1918),
         sex == "female",
         age > 10) |> 
  ggplot(aes(x = age, y = dx, color = as.factor(year))) +
  geom_point() +
  geom_smooth(span = .15) +
  theme_minimal()
```




























